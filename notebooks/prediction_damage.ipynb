{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee77590",
   "metadata": {},
   "source": [
    "Tạo random 100 dữ liệu mới "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Số dòng dữ liệu mới bạn muốn tạo\n",
    "n_samples = 100\n",
    "\n",
    "# Tạo dữ liệu mẫu\n",
    "df_new = pd.DataFrame({\n",
    "    'traffic_control_device': np.random.choice(['SIGNAL', 'STOP', 'NONE'], n_samples),\n",
    "    'weather_condition': np.random.choice(['CLEAR', 'RAIN', 'SNOW'], n_samples),\n",
    "    'lighting_condition': np.random.choice(['DAYLIGHT', 'DARK'], n_samples),\n",
    "    'first_crash_type': np.random.choice(['REAR END', 'ANGLE', 'SIDESWIPE'], n_samples),\n",
    "    'trafficway_type': np.random.choice(['ONE-WAY', 'TWO-WAY'], n_samples),\n",
    "    'alignment': np.random.choice(['STRAIGHT', 'CURVED'], n_samples),\n",
    "    'roadway_surface_cond': np.random.choice(['DRY', 'WET'], n_samples),\n",
    "    'road_defect': np.random.choice(['NONE', 'HOLE'], n_samples),\n",
    "    'crash_type': np.random.choice(['COLLISION', 'NON-COLLISION'], n_samples),\n",
    "    'intersection_related_i': np.random.choice(['Y', 'N'], n_samples),\n",
    "    'damage': np.random.choice(['OVER $1500', 'UNDER $1500'], n_samples),\n",
    "    'prim_contributory_cause': np.random.choice(['DISTRACTION', 'SPEEDING'], n_samples),\n",
    "    'num_units': np.random.randint(1, 5, n_samples),\n",
    "    'most_severe_injury': np.random.choice(['NO INJURY', 'INCAPACITATING INJURY'], n_samples),\n",
    "    'injuries_total': np.random.randint(0, 4, n_samples),\n",
    "    'injuries_fatal': np.random.randint(0, 1, n_samples),\n",
    "    'injuries_incapacitating': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_non_incapacitating': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_reported_not_evident': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_no_indication': np.random.randint(0, 3, n_samples),\n",
    "    'crash_hour': np.random.randint(0, 24, n_samples),\n",
    "    'crash_day_of_week': np.random.randint(1, 8, n_samples),   # 1–7\n",
    "    'crash_month': np.random.randint(1, 13, n_samples),        # 1–12\n",
    "})\n",
    "\n",
    "# Lưu file CSV\n",
    "df_new.to_csv('new_data_simulated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cc748",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu mới "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a5b4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Đọc dataset từ file CSV\n",
    "df = pd.read_csv(r\"D:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\data\\new_data_simulated.csv\", encoding='utf-8')  # Thử với utf-8 hoặc ISO-8859-1\n",
    "\n",
    "# Xóa cột \"crash_date\" nếu tồn tại\n",
    "if \"crash_date\" in df.columns:\n",
    "    df = df.drop(columns=[\"crash_date\"])\n",
    "\n",
    "if \"damage\" in df.columns:\n",
    "    df = df.drop(columns=[\"damage\"])\n",
    "\n",
    "# Các cột cần mã hóa\n",
    "categorical_columns = [\n",
    "    \"traffic_control_device\", \"weather_condition\", \"lighting_condition\", \"first_crash_type\", \n",
    "    \"trafficway_type\", \"alignment\", \"roadway_surface_cond\", \"road_defect\", \"crash_type\", \n",
    "    \"intersection_related_i\", \"prim_contributory_cause\", \"most_severe_injury\"\n",
    "]\n",
    "\n",
    "# Dictionary để lưu các label encoder\n",
    "decoders = {}\n",
    "\n",
    "# Mã hóa từng cột\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])  # Thay đổi trực tiếp giá trị trong cột\n",
    "    decoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))  # Lưu mapping cho báo cáo\n",
    "\n",
    "# Xuất báo cáo mã hóa\n",
    "encoding_report = \"\"\"Báo cáo Mã hóa Categorical Data\\n\\n\"\"\"\n",
    "for col, mapping in decoders.items():\n",
    "    encoding_report += f\"Cột: {col}\\n\"\n",
    "    for key, value in mapping.items():\n",
    "        encoding_report += f\"  {key}: {value}\\n\"\n",
    "    encoding_report += \"\\n\"\n",
    "\n",
    "# Lưu dataset đã mã hóa\n",
    "df.to_csv('new_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f43555e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import networkx as nx \n",
    "from itertools import combinations\n",
    "from torch_geometric.data import Data \n",
    "from model import GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cada523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dataset\n",
    "file_path = r'D:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\data\\new_data_cleaned.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bbc35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã tạo đồ thị với 100 nút và 4156 cạnh.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in df.iterrows():\n",
    "    G.add_node(index, **row.to_dict())\n",
    "\n",
    "def is_similar(accident1, accident2):\n",
    "    return (\n",
    "        abs(accident1['crash_hour'] - accident2['crash_hour']) <= 1 or\n",
    "        accident1['crash_month'] == accident2['crash_month'] or\n",
    "        accident1['crash_day_of_week'] == accident2['crash_day_of_week'] or\n",
    "        accident1['trafficway_type'] == accident2['trafficway_type'] or\n",
    "        accident1['first_crash_type'] == accident2['first_crash_type'] or\n",
    "        accident1['injuries_no_indication'] == accident2['injuries_no_indication']\n",
    "    )\n",
    "\n",
    "for u, v in combinations(G.nodes(data=True), 2):\n",
    "    if is_similar(u[1], v[1]):\n",
    "        G.add_edge(u[0], v[0])\n",
    "\n",
    "print(f\"✅ Đã tạo đồ thị với {G.number_of_nodes()} nút và {G.number_of_edges()} cạnh.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "812aec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def networkx_to_pyg_inference(G):\n",
    "    feature_attrs = list(next(iter(G.nodes(data=True)))[1].keys())\n",
    "\n",
    "    features = [\n",
    "        [float(data[attr]) for attr in feature_attrs]\n",
    "        for _, data in G.nodes(data=True)\n",
    "    ]\n",
    "\n",
    "    x = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "    node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    edge_index = torch.tensor(\n",
    "        [[node_mapping[u], node_mapping[v]] for u, v in G.edges()],\n",
    "        dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data_new = networkx_to_pyg_inference(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42bddece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (gat1): GATConv(22, 16, heads=8)\n",
       "  (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (gat2): GATConv(128, 16, heads=4)\n",
       "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (gat3): GATConv(64, 3, heads=1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAT(in_features=22, hidden_dim=16, out_features=3, heads=8).to(device)\n",
    "model.load_state_dict(torch.load('gat_model.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06217ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(data_new.x.to(device), data_new.edge_index.to(device))\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "df['predicted_damage'] = pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c58a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    predicted_damage predicted_damage_label\n",
      "0                  0           $500 OR LESS\n",
      "1                  0           $500 OR LESS\n",
      "2                  0           $500 OR LESS\n",
      "3                  0           $500 OR LESS\n",
      "4                  0           $500 OR LESS\n",
      "..               ...                    ...\n",
      "95                 1          $501 - $1,500\n",
      "96                 1          $501 - $1,500\n",
      "97                 1          $501 - $1,500\n",
      "98                 1          $501 - $1,500\n",
      "99                 1          $501 - $1,500\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mapping số về chuỗi như trong cột damage gốc\n",
    "damage_mapping = {\n",
    "    0: \"$500 OR LESS\",\n",
    "    1: \"$501 - $1,500\",\n",
    "    2: \"OVER $1,500\"\n",
    "}\n",
    "\n",
    "# Tạo cột mới với nhãn dạng chuỗi\n",
    "df['predicted_damage_label'] = df['predicted_damage'].map(damage_mapping)\n",
    "\n",
    "# Hiển thị 5 dòng đầu để kiểm tra\n",
    "print(df[['predicted_damage', 'predicted_damage_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe7eb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def analyze_high_damage_nodes(G, label_attr='predicted_damage', high_level=1, top_k=5):\n",
    "    # Bước 1: Lọc các node có damage cao\n",
    "    high_damage_nodes = [n for n, data in G.nodes(data=True) if data.get(label_attr) == high_level]\n",
    "\n",
    "    # Bước 2: Thống kê các feature xuất hiện trong nhóm này\n",
    "    feature_counters = defaultdict(Counter)\n",
    "\n",
    "    for n in high_damage_nodes:\n",
    "        node_data = G.nodes[n]\n",
    "        for attr, value in node_data.items():\n",
    "            if attr != label_attr:\n",
    "                feature_counters[attr][value] += 1\n",
    "\n",
    "    # Bước 3: In ra top K giá trị phổ biến nhất cho từng feature\n",
    "    print(f\"\\n📊 Top nguyên nhân thường thấy khi `{label_attr} = {high_level}`:\\n\")\n",
    "    for attr, counter in feature_counters.items():\n",
    "        print(f\"- {attr}:\")\n",
    "        for val, freq in counter.most_common(top_k):\n",
    "            print(f\"   • {val}: {freq} lần\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9438315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top nguyên nhân thường thấy khi `predicted_damage = 1`:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Giả sử bạn đã có đồ thị G\n",
    "analyze_high_damage_nodes(G, label_attr='predicted_damage', high_level=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

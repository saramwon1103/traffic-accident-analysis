{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee77590",
   "metadata": {},
   "source": [
    "Tạo random 100 dữ liệu mới "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Số dòng dữ liệu mới bạn muốn tạo\n",
    "n_samples = 100\n",
    "\n",
    "# Tạo dữ liệu mẫu\n",
    "df_new = pd.DataFrame({\n",
    "    'traffic_control_device': np.random.choice(['SIGNAL', 'STOP', 'NONE'], n_samples),\n",
    "    'weather_condition': np.random.choice(['CLEAR', 'RAIN', 'SNOW'], n_samples),\n",
    "    'lighting_condition': np.random.choice(['DAYLIGHT', 'DARK'], n_samples),\n",
    "    'first_crash_type': np.random.choice(['REAR END', 'ANGLE', 'SIDESWIPE'], n_samples),\n",
    "    'trafficway_type': np.random.choice(['ONE-WAY', 'TWO-WAY'], n_samples),\n",
    "    'alignment': np.random.choice(['STRAIGHT', 'CURVED'], n_samples),\n",
    "    'roadway_surface_cond': np.random.choice(['DRY', 'WET'], n_samples),\n",
    "    'road_defect': np.random.choice(['NONE', 'HOLE'], n_samples),\n",
    "    'crash_type': np.random.choice(['COLLISION', 'NON-COLLISION'], n_samples),\n",
    "    'intersection_related_i': np.random.choice(['Y', 'N'], n_samples),\n",
    "    'damage': np.random.choice(['OVER $1500', 'UNDER $1500'], n_samples),\n",
    "    'prim_contributory_cause': np.random.choice(['DISTRACTION', 'SPEEDING'], n_samples),\n",
    "    'num_units': np.random.randint(1, 5, n_samples),\n",
    "    'most_severe_injury': np.random.choice(['NO INJURY', 'INCAPACITATING INJURY'], n_samples),\n",
    "    'injuries_total': np.random.randint(0, 4, n_samples),\n",
    "    'injuries_fatal': np.random.randint(0, 1, n_samples),\n",
    "    'injuries_incapacitating': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_non_incapacitating': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_reported_not_evident': np.random.randint(0, 2, n_samples),\n",
    "    'injuries_no_indication': np.random.randint(0, 3, n_samples),\n",
    "    'crash_hour': np.random.randint(0, 24, n_samples),\n",
    "    'crash_day_of_week': np.random.randint(1, 8, n_samples),   # 1–7\n",
    "    'crash_month': np.random.randint(1, 13, n_samples),        # 1–12\n",
    "})\n",
    "\n",
    "# Lưu file CSV\n",
    "df_new.to_csv('new_data_simulated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cc748",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu mới "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b4adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Đọc dataset từ file CSV\n",
    "df = pd.read_csv(r\"D:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\data\\new_data_simulated.csv\", encoding='utf-8')  # Thử với utf-8 hoặc ISO-8859-1\n",
    "\n",
    "# Xóa cột \"crash_date\" nếu tồn tại\n",
    "if \"crash_date\" in df.columns:\n",
    "    df = df.drop(columns=[\"crash_date\"])\n",
    "\n",
    "if \"damage\" in df.columns:\n",
    "    df = df.drop(columns=[\"damage\"])\n",
    "\n",
    "# Các cột cần mã hóa\n",
    "categorical_columns = [\n",
    "    \"traffic_control_device\", \"weather_condition\", \"lighting_condition\", \"first_crash_type\", \n",
    "    \"trafficway_type\", \"alignment\", \"roadway_surface_cond\", \"road_defect\", \"crash_type\", \n",
    "    \"intersection_related_i\", \"prim_contributory_cause\", \"most_severe_injury\"\n",
    "]\n",
    "\n",
    "# Dictionary để lưu các label encoder\n",
    "decoders = {}\n",
    "\n",
    "# Mã hóa từng cột\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])  # Thay đổi trực tiếp giá trị trong cột\n",
    "    decoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))  # Lưu mapping cho báo cáo\n",
    "\n",
    "# Lưu dataset đã mã hóa\n",
    "df.to_csv('new_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43555e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import networkx as nx \n",
    "from itertools import combinations\n",
    "from torch_geometric.data import Data \n",
    "from model import GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cada523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dataset\n",
    "file_path = r'D:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\data\\new_data_cleaned.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc35ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã tạo đồ thị với 100 nút và 4156 cạnh.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G = nx.Graph()\n",
    "for index, row in df.iterrows():\n",
    "    G.add_node(index, **row.to_dict())\n",
    "\n",
    "def is_similar(accident1, accident2):\n",
    "    return (\n",
    "        abs(accident1['crash_hour'] - accident2['crash_hour']) <= 1 or\n",
    "        accident1['crash_month'] == accident2['crash_month'] or\n",
    "        accident1['crash_day_of_week'] == accident2['crash_day_of_week'] or\n",
    "        accident1['trafficway_type'] == accident2['trafficway_type'] or\n",
    "        accident1['first_crash_type'] == accident2['first_crash_type'] or\n",
    "        accident1['injuries_no_indication'] == accident2['injuries_no_indication']\n",
    "    )\n",
    "\n",
    "for u, v in combinations(G.nodes(data=True), 2):\n",
    "    if is_similar(u[1], v[1]):\n",
    "        G.add_edge(u[0], v[0])\n",
    "\n",
    "print(f\"Đã tạo đồ thị với {G.number_of_nodes()} nút và {G.number_of_edges()} cạnh.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812aec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def networkx_to_pyg_inference(G):\n",
    "    feature_attrs = list(next(iter(G.nodes(data=True)))[1].keys())\n",
    "\n",
    "    features = [\n",
    "        [float(data[attr]) for attr in feature_attrs]\n",
    "        for _, data in G.nodes(data=True)\n",
    "    ]\n",
    "\n",
    "    x = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "    node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    edge_index = torch.tensor(\n",
    "        [[node_mapping[u], node_mapping[v]] for u, v in G.edges()],\n",
    "        dtype=torch.long\n",
    "    ).t().contiguous()\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data_new = networkx_to_pyg_inference(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bddece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (gat1): GATConv(22, 16, heads=8)\n",
       "  (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (gat2): GATConv(128, 16, heads=4)\n",
       "  (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (gat3): GATConv(64, 3, heads=1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GAT(in_features=22, hidden_dim=16, out_features=3, heads=8).to(device)\n",
    "model.load_state_dict(torch.load('gat_model.pth', map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06217ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(data_new.x.to(device), data_new.edge_index.to(device))\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "df['predicted_damage'] = pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36da5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 has predicted_damage = 0\n",
      "Node 1 has predicted_damage = 0\n",
      "Node 2 has predicted_damage = 0\n",
      "Node 3 has predicted_damage = 0\n",
      "Node 4 has predicted_damage = 0\n",
      "Node 5 has predicted_damage = 0\n",
      "Node 6 has predicted_damage = 0\n",
      "Node 7 has predicted_damage = 0\n",
      "Node 8 has predicted_damage = 0\n",
      "Node 9 has predicted_damage = 0\n",
      "Node 10 has predicted_damage = 0\n",
      "Node 11 has predicted_damage = 0\n",
      "Node 12 has predicted_damage = 0\n",
      "Node 13 has predicted_damage = 0\n",
      "Node 14 has predicted_damage = 0\n",
      "Node 15 has predicted_damage = 0\n",
      "Node 16 has predicted_damage = 0\n",
      "Node 17 has predicted_damage = 0\n",
      "Node 18 has predicted_damage = 0\n",
      "Node 19 has predicted_damage = 0\n",
      "Node 20 has predicted_damage = 0\n",
      "Node 21 has predicted_damage = 0\n",
      "Node 22 has predicted_damage = 0\n",
      "Node 23 has predicted_damage = 0\n",
      "Node 24 has predicted_damage = 0\n",
      "Node 25 has predicted_damage = 0\n",
      "Node 26 has predicted_damage = 0\n",
      "Node 27 has predicted_damage = 0\n",
      "Node 28 has predicted_damage = 0\n",
      "Node 29 has predicted_damage = 0\n",
      "Node 30 has predicted_damage = 0\n",
      "Node 31 has predicted_damage = 0\n",
      "Node 32 has predicted_damage = 0\n",
      "Node 33 has predicted_damage = 0\n",
      "Node 34 has predicted_damage = 0\n",
      "Node 35 has predicted_damage = 0\n",
      "Node 36 has predicted_damage = 0\n",
      "Node 37 has predicted_damage = 0\n",
      "Node 38 has predicted_damage = 0\n",
      "Node 39 has predicted_damage = 0\n",
      "Node 40 has predicted_damage = 0\n",
      "Node 41 has predicted_damage = 0\n",
      "Node 42 has predicted_damage = 0\n",
      "Node 43 has predicted_damage = 0\n",
      "Node 44 has predicted_damage = 0\n",
      "Node 45 has predicted_damage = 0\n",
      "Node 46 has predicted_damage = 0\n",
      "Node 47 has predicted_damage = 0\n",
      "Node 48 has predicted_damage = 0\n",
      "Node 49 has predicted_damage = 0\n",
      "Node 50 has predicted_damage = 0\n",
      "Node 51 has predicted_damage = 0\n",
      "Node 52 has predicted_damage = 0\n",
      "Node 53 has predicted_damage = 0\n",
      "Node 54 has predicted_damage = 0\n",
      "Node 55 has predicted_damage = 0\n",
      "Node 56 has predicted_damage = 0\n",
      "Node 57 has predicted_damage = 0\n",
      "Node 58 has predicted_damage = 0\n",
      "Node 59 has predicted_damage = 0\n",
      "Node 60 has predicted_damage = 1\n",
      "Node 61 has predicted_damage = 1\n",
      "Node 62 has predicted_damage = 0\n",
      "Node 63 has predicted_damage = 0\n",
      "Node 64 has predicted_damage = 1\n",
      "Node 65 has predicted_damage = 1\n",
      "Node 66 has predicted_damage = 1\n",
      "Node 67 has predicted_damage = 1\n",
      "Node 68 has predicted_damage = 1\n",
      "Node 69 has predicted_damage = 1\n",
      "Node 70 has predicted_damage = 1\n",
      "Node 71 has predicted_damage = 1\n",
      "Node 72 has predicted_damage = 1\n",
      "Node 73 has predicted_damage = 1\n",
      "Node 74 has predicted_damage = 1\n",
      "Node 75 has predicted_damage = 1\n",
      "Node 76 has predicted_damage = 1\n",
      "Node 77 has predicted_damage = 1\n",
      "Node 78 has predicted_damage = 1\n",
      "Node 79 has predicted_damage = 1\n",
      "Node 80 has predicted_damage = 1\n",
      "Node 81 has predicted_damage = 1\n",
      "Node 82 has predicted_damage = 1\n",
      "Node 83 has predicted_damage = 1\n",
      "Node 84 has predicted_damage = 1\n",
      "Node 85 has predicted_damage = 1\n",
      "Node 86 has predicted_damage = 1\n",
      "Node 87 has predicted_damage = 1\n",
      "Node 88 has predicted_damage = 1\n",
      "Node 89 has predicted_damage = 1\n",
      "Node 90 has predicted_damage = 1\n",
      "Node 91 has predicted_damage = 1\n",
      "Node 92 has predicted_damage = 1\n",
      "Node 93 has predicted_damage = 1\n",
      "Node 94 has predicted_damage = 1\n",
      "Node 95 has predicted_damage = 1\n",
      "Node 96 has predicted_damage = 1\n",
      "Node 97 has predicted_damage = 1\n",
      "Node 98 has predicted_damage = 1\n",
      "Node 99 has predicted_damage = 1\n"
     ]
    }
   ],
   "source": [
    "# Thêm giá trị predicted_damage vào đồ thị\n",
    "for i, pred in enumerate(pred.cpu().numpy()):\n",
    "    G.nodes[i]['predicted_damage'] = pred\n",
    "\n",
    "# Kiểm tra lại giá trị đã được gán đúng chưa\n",
    "for i in range(len(df)):\n",
    "    print(f\"Node {i} has predicted_damage = {G.nodes[i].get('predicted_damage')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    predicted_damage predicted_damage_label\n",
      "0                  0           $500 OR LESS\n",
      "1                  0           $500 OR LESS\n",
      "2                  0           $500 OR LESS\n",
      "3                  0           $500 OR LESS\n",
      "4                  0           $500 OR LESS\n",
      "..               ...                    ...\n",
      "95                 1          $501 - $1,500\n",
      "96                 1          $501 - $1,500\n",
      "97                 1          $501 - $1,500\n",
      "98                 1          $501 - $1,500\n",
      "99                 1          $501 - $1,500\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mapping số về chuỗi như trong cột damage gốc\n",
    "damage_mapping = {\n",
    "    0: \"$500 OR LESS\",\n",
    "    1: \"$501 - $1,500\",\n",
    "    2: \"OVER $1,500\"\n",
    "}\n",
    "\n",
    "# Tạo cột mới với nhãn dạng chuỗi\n",
    "df['predicted_damage_label'] = df['predicted_damage'].map(damage_mapping)\n",
    "\n",
    "print(df[['predicted_damage', 'predicted_damage_label']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be283f",
   "metadata": {},
   "source": [
    "Suy ra nguyên nhân dẫn đến các dự đoán damage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4d1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def analyze_high_damage_nodes(G, label_attr='predicted_damage', high_level=1, top_k=3):\n",
    "    # Bước 1: Lọc các node có predicted_damage bằng high_level\n",
    "    high_damage_nodes = [n for n, data in G.nodes(data=True) if data.get(label_attr) == high_level]\n",
    "\n",
    "    # Kiểm tra nếu không có node nào\n",
    "    if not high_damage_nodes:\n",
    "        print(f\"No nodes found with {label_attr} = {high_level}\")\n",
    "        return\n",
    "\n",
    "    # Bước 2: Thống kê các feature xuất hiện trong nhóm này\n",
    "    feature_counters = defaultdict(Counter)\n",
    "\n",
    "    for n in high_damage_nodes:\n",
    "        node_data = G.nodes[n]\n",
    "        for attr, value in node_data.items():\n",
    "            if attr != label_attr:\n",
    "                feature_counters[attr][value] += 1\n",
    "\n",
    "    # Bước 3: In ra top K giá trị phổ biến nhất cho từng feature\n",
    "    print(f\"\\nTop nguyên nhân thường thấy khi `{label_attr} = {high_level}`:\\n\")\n",
    "    for attr, counter in feature_counters.items():\n",
    "        print(f\"- {attr}:\")\n",
    "        for val, freq in counter.most_common(top_k):\n",
    "            print(f\"   • {val}: {freq} lần\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84058824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top nguyên nhân thường thấy khi `predicted_damage = 0`:\n",
      "\n",
      "- traffic_control_device:\n",
      "   • 0: 28 lần\n",
      "   • 1: 26 lần\n",
      "   • 2: 8 lần\n",
      "\n",
      "- weather_condition:\n",
      "   • 2: 28 lần\n",
      "   • 1: 18 lần\n",
      "   • 0: 16 lần\n",
      "\n",
      "- lighting_condition:\n",
      "   • 0: 34 lần\n",
      "   • 1: 28 lần\n",
      "\n",
      "- first_crash_type:\n",
      "   • 1: 23 lần\n",
      "   • 2: 20 lần\n",
      "   • 0: 19 lần\n",
      "\n",
      "- trafficway_type:\n",
      "   • 0: 32 lần\n",
      "   • 1: 30 lần\n",
      "\n",
      "- alignment:\n",
      "   • 0: 32 lần\n",
      "   • 1: 30 lần\n",
      "\n",
      "- roadway_surface_cond:\n",
      "   • 1: 31 lần\n",
      "   • 0: 31 lần\n",
      "\n",
      "- road_defect:\n",
      "   • 0: 34 lần\n",
      "   • 1: 28 lần\n",
      "\n",
      "- crash_type:\n",
      "   • 1: 37 lần\n",
      "   • 0: 25 lần\n",
      "\n",
      "- intersection_related_i:\n",
      "   • 0: 33 lần\n",
      "   • 1: 29 lần\n",
      "\n",
      "- prim_contributory_cause:\n",
      "   • 0: 32 lần\n",
      "   • 1: 30 lần\n",
      "\n",
      "- num_units:\n",
      "   • 2: 19 lần\n",
      "   • 1: 16 lần\n",
      "   • 3: 14 lần\n",
      "\n",
      "- most_severe_injury:\n",
      "   • 1: 34 lần\n",
      "   • 0: 28 lần\n",
      "\n",
      "- injuries_total:\n",
      "   • 2: 20 lần\n",
      "   • 3: 17 lần\n",
      "   • 1: 15 lần\n",
      "\n",
      "- injuries_fatal:\n",
      "   • 0: 62 lần\n",
      "\n",
      "- injuries_incapacitating:\n",
      "   • 1: 31 lần\n",
      "   • 0: 31 lần\n",
      "\n",
      "- injuries_non_incapacitating:\n",
      "   • 1: 32 lần\n",
      "   • 0: 30 lần\n",
      "\n",
      "- injuries_reported_not_evident:\n",
      "   • 0: 38 lần\n",
      "   • 1: 24 lần\n",
      "\n",
      "- injuries_no_indication:\n",
      "   • 1: 25 lần\n",
      "   • 2: 19 lần\n",
      "   • 0: 18 lần\n",
      "\n",
      "- crash_hour:\n",
      "   • 19: 6 lần\n",
      "   • 13: 5 lần\n",
      "   • 9: 5 lần\n",
      "\n",
      "- crash_day_of_week:\n",
      "   • 3: 14 lần\n",
      "   • 2: 11 lần\n",
      "   • 4: 10 lần\n",
      "\n",
      "- crash_month:\n",
      "   • 9: 7 lần\n",
      "   • 4: 7 lần\n",
      "   • 6: 7 lần\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_high_damage_nodes(G, label_attr='predicted_damage', high_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7438d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top nguyên nhân thường thấy khi `predicted_damage = 1`:\n",
      "\n",
      "- traffic_control_device:\n",
      "   • 1: 13 lần\n",
      "   • 2: 13 lần\n",
      "   • 0: 12 lần\n",
      "\n",
      "- weather_condition:\n",
      "   • 0: 15 lần\n",
      "   • 1: 13 lần\n",
      "   • 2: 10 lần\n",
      "\n",
      "- lighting_condition:\n",
      "   • 0: 22 lần\n",
      "   • 1: 16 lần\n",
      "\n",
      "- first_crash_type:\n",
      "   • 1: 16 lần\n",
      "   • 0: 14 lần\n",
      "   • 2: 8 lần\n",
      "\n",
      "- trafficway_type:\n",
      "   • 0: 21 lần\n",
      "   • 1: 17 lần\n",
      "\n",
      "- alignment:\n",
      "   • 0: 20 lần\n",
      "   • 1: 18 lần\n",
      "\n",
      "- roadway_surface_cond:\n",
      "   • 0: 25 lần\n",
      "   • 1: 13 lần\n",
      "\n",
      "- road_defect:\n",
      "   • 1: 20 lần\n",
      "   • 0: 18 lần\n",
      "\n",
      "- crash_type:\n",
      "   • 1: 24 lần\n",
      "   • 0: 14 lần\n",
      "\n",
      "- intersection_related_i:\n",
      "   • 0: 19 lần\n",
      "   • 1: 19 lần\n",
      "\n",
      "- prim_contributory_cause:\n",
      "   • 0: 23 lần\n",
      "   • 1: 15 lần\n",
      "\n",
      "- num_units:\n",
      "   • 4: 14 lần\n",
      "   • 2: 10 lần\n",
      "   • 3: 8 lần\n",
      "\n",
      "- most_severe_injury:\n",
      "   • 1: 21 lần\n",
      "   • 0: 17 lần\n",
      "\n",
      "- injuries_total:\n",
      "   • 1: 11 lần\n",
      "   • 3: 11 lần\n",
      "   • 2: 9 lần\n",
      "\n",
      "- injuries_fatal:\n",
      "   • 0: 38 lần\n",
      "\n",
      "- injuries_incapacitating:\n",
      "   • 0: 19 lần\n",
      "   • 1: 19 lần\n",
      "\n",
      "- injuries_non_incapacitating:\n",
      "   • 1: 21 lần\n",
      "   • 0: 17 lần\n",
      "\n",
      "- injuries_reported_not_evident:\n",
      "   • 1: 27 lần\n",
      "   • 0: 11 lần\n",
      "\n",
      "- injuries_no_indication:\n",
      "   • 1: 15 lần\n",
      "   • 0: 13 lần\n",
      "   • 2: 10 lần\n",
      "\n",
      "- crash_hour:\n",
      "   • 8: 4 lần\n",
      "   • 23: 4 lần\n",
      "   • 20: 3 lần\n",
      "\n",
      "- crash_day_of_week:\n",
      "   • 5: 8 lần\n",
      "   • 2: 8 lần\n",
      "   • 7: 5 lần\n",
      "\n",
      "- crash_month:\n",
      "   • 3: 6 lần\n",
      "   • 9: 5 lần\n",
      "   • 12: 5 lần\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_high_damage_nodes(G, label_attr='predicted_damage', high_level=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f43555e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import networkx as nx \n",
    "from itertools import combinations\n",
    "from torch_geometric.data import Data \n",
    "from model import GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cada523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dataset\n",
    "file_path = r'D:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\data\\new_data_template.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bbc35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for index, row in df.iterrows():\n",
    "    G.add_node(index, **row.to_dict())\n",
    "\n",
    "def is_similar(acc1, acc2):\n",
    "    return (\n",
    "        abs(acc1['crash_hour'] - acc2['crash_hour']) <= 1 or\n",
    "        acc1['crash_month'] == acc2['crash_month'] or\n",
    "        acc1['crash_day_of_week'] == acc2['crash_day_of_week'] or\n",
    "        acc1['trafficway_type'] == acc2['trafficway_type'] or\n",
    "        acc1['first_crash_type'] == acc2['first_crash_type']\n",
    "    )\n",
    "\n",
    "for u, v in combinations(G.nodes(data=True), 2):\n",
    "    if is_similar(u[1], v[1]):\n",
    "        G.add_edge(u[0], v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "812aec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def networkx_to_pyg(G):\n",
    "    node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    edge_index = torch.tensor([[node_mapping[u], node_mapping[v]] for u, v in G.edges()], dtype=torch.long).t().contiguous()\n",
    "\n",
    "    features = []\n",
    "    for _, data in G.nodes(data=True):\n",
    "        node_features = [data[attr] for attr in data]\n",
    "        features.append(node_features)\n",
    "\n",
    "    x = torch.tensor(features, dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = networkx_to_pyg(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42bddece",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LayerNorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerNorm\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGAT\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgat_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32md:\\Năm 3 - HK2\\Mạng xã hội\\traffic-accident-analysis\\notebooks\\model.py:10\u001b[0m, in \u001b[0;36mGAT.__init__\u001b[1;34m(self, in_features, hidden_dim, out_features, heads)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28msuper\u001b[39m(GAT, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat1 \u001b[38;5;241m=\u001b[39m GATConv(in_features, hidden_dim, heads\u001b[38;5;241m=\u001b[39mheads, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1 \u001b[38;5;241m=\u001b[39m \u001b[43mLayerNorm\u001b[49m(hidden_dim \u001b[38;5;241m*\u001b[39m heads)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat2 \u001b[38;5;241m=\u001b[39m GATConv(hidden_dim \u001b[38;5;241m*\u001b[39m heads, hidden_dim, heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2 \u001b[38;5;241m=\u001b[39m LayerNorm(hidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LayerNorm' is not defined"
     ]
    }
   ],
   "source": [
    "from model import GAT\n",
    "import torch\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "model = GAT(in_features=23, hidden_dim=16, out_features=3)\n",
    "model.load_state_dict(torch.load('gat_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8e4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=2):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06217ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Loss: 2.6882 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 020 | Loss: 1.1694 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 030 | Loss: 0.7998 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 040 | Loss: 0.8707 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 050 | Loss: 0.8049 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 060 | Loss: 0.7995 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 070 | Loss: 0.7996 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 080 | Loss: 0.7970 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 090 | Loss: 0.7959 | Test Acc: 0.7025 | F1: 0.2751\n",
      "Epoch 100 | Loss: 0.7956 | Test Acc: 0.7025 | F1: 0.2751\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT(in_channels=data.num_node_features, hidden_channels=32, out_channels=4).to(device)  # 4 mức độ damage\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())\n",
    "    f1 = f1_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu(), average='macro')\n",
    "    return acc, f1\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    acc, f1 = test()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Test Acc: {acc:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735f1bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán damage (dạng text): ['OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500', 'OVER $1,500']\n"
     ]
    }
   ],
   "source": [
    "# Mapping ngược (giả sử encoding gốc như sau — bạn có thể chỉnh lại nếu khác):\n",
    "damage_label_map = {\n",
    "    0: \"$500 OR LESS\",\n",
    "    1: \"$501 - $1,500\",\n",
    "    2: \"OVER $1,500\",\n",
    "    3: \"0\"\n",
    "}\n",
    "\n",
    "# Dự đoán trên toàn bộ tập dữ liệu\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Chuyển nhãn số thành nhãn gốc\n",
    "decoded_preds = [damage_label_map[label] for label in pred]\n",
    "\n",
    "# Ví dụ: Xem dự đoán đầu tiên\n",
    "print(f\"Dự đoán damage (dạng text): {decoded_preds[:10]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
